{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/High-Dimensional-Deep-Learning/blob/master/AutoEncoder/Autoencoders_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy.\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir image\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_decoder.png\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_vae.png\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_2.svg\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_3.svg\n",
    "! mkdir solutions\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_decoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_encoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/convolutional_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoded_images_both_method.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoder_vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/generate_single_sample.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/simple_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/train_denoise_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is an Autoencoder ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"text-align:center\"><img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" style=\"float:center; display: inline\" alt=\"schema\"/></P>\n",
    "<i>Autoencoder architecture</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective \n",
    "\n",
    "During this TP  we will build different autoencoders with Keras and Tensorflow. Here are the main objectives :\n",
    "\n",
    "* Build a autoencoder based on simple perceptron layers.\n",
    "* Add regularization on layers and understand its effects.\n",
    "* Build a convolutional autoencoder.\n",
    "* Use a convolutional autoencoder to solve denoising problems.\n",
    "* Manipulate the library in order to get and observe the result at different points of the dataflow.\n",
    "\n",
    "\n",
    "The dataset used all along this TP is the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.regularizers as kr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "As we won't apply any supervised algorithm in this TP, we do not need to load the `Y` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous TP, it is better to normalize the dataset before to apply algorithm on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "fig  = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "x = kpi.img_to_array(x_train[0])\n",
    "ax.imshow(x[:,:,0], interpolation='nearest', cmap=\"binary\")\n",
    "ax.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple autoencoder\n",
    "\n",
    "We will first build a very simple architecture where :\n",
    "\n",
    "* the **encoder layer** : is a `Dense` layer composed of 32 neurons (the latent variable) with a `Relu` activation function :\n",
    "$$relu(x) = max(0,x)$$\n",
    "* the **decoded layer** : is a `Dense` layer composed of  784 neurons (the input dimension) with a `Sigmoid`activation function.\n",
    "$$sigmoid(x) = \\frac{1}{1+\\text{e}^x}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first reshape the data form to be 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_flatten = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "x_train_flatten.shape, x_test_flatten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : write the simple model described above in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = 32\n",
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/simple_autoencoder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then learn the model. Note that the target variable is the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_flatten, x_train_flatten, epochs=25, batch_size=256, validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : We use the binary cross entropy here as in the original paper [1](https://arxiv.org/pdf/1312.6114.pdf). Does it seem an intuitive choice? Why?\n",
    "How is the loss evolving during training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check outputs\n",
    "\n",
    "We will no check how the model performs. We produce first the encoded-decoded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test_imgs = autoencoder.predict(x_test_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function displays both the input and the output of the autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_test_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about this results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Check latent variable\n",
    "\n",
    "The Keras model that we have written above does not allow us to retrieve the latent variables. \n",
    "In order to do so, we have to re-write the model in order to get this variable later.\n",
    "\n",
    "We first write the encoder part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = km.Sequential(name=\"EncoderModel\")\n",
    "encoder.add(kl.Dense(n_latent, activation='relu', input_shape=(n_input,),name=\"encoder_layer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then write the decoder as  another independent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = km.Sequential(name=\"DecoderModel\")\n",
    "decoder.add(kl.Dense(n_input, activation='sigmoid', input_shape =(n_latent,), name = \"decoded_layer\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally write the autoencoder model by adding the two previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = km.Sequential(name=\"EncoderDecoder\")\n",
    "autoencoder.add(encoder)\n",
    "autoencoder.add(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is well composed of the association of the two previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the two sub models with the following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.get_layer(\"EncoderModel\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can then be learned by the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_flatten, x_train_flatten, epochs=25, batch_size=256, validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the loss value of the model ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access and produce easily the latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test_flatten)\n",
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display encoded imgs\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(encoded_imgs[i].reshape(8, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce the decoded images by :\n",
    "* Using the decoded part on the encoded images.\n",
    "* Using the whole architecture on the original image.\n",
    "\n",
    "**Exercise** : Check that both methods produce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/decoded_images_both_method.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example the autoencoder is only constrained by the size of the hidden layer. \n",
    "\n",
    "In the following figure you can see the distribution of the number of latent variables set to zero for the 10.000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(np.sum(encoded_imgs==0,axis=1), width=0.9, bins=np.arange(-0.5,10.5,1))\n",
    "ax.set_xticks(np.arange(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get a sparser encoded representation of the images is to add a *sparsity constraint* on the activity function of the hidden layer. \n",
    "\n",
    "Regularizers enable to avoid overfitting by adding some constraint on the weights we want to control. \n",
    "\n",
    "Cost function = Loss (say, binary cross-entropy) + Regularization term \n",
    "\n",
    "Cost function = Loss + $\\lambda$ $\\sum w$, where in our case $\\lambda = 10e-5$ and $w$ are the weights of the encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10e-5\n",
    "\n",
    "sparse_encoder = km.Sequential(name=\"SparseEncoderModel\")\n",
    "sparse_encoder.add(kl.Dense(n_latent, activation='relu', input_shape=(n_input,), activity_regularizer=kr.l1(l) ,name=\"encoder_layer\"))\n",
    "\n",
    "sparse_decoder = km.Sequential(name=\"SparseDecoderModel\")\n",
    "sparse_decoder.add(kl.Dense(n_input, activation='sigmoid', input_shape =(n_latent,), name = \"decoded_layer\" ))\n",
    "\n",
    "sparse_autoencoder = km.Sequential(name=\"SparseEncoderDecoder\")\n",
    "sparse_autoencoder.add(sparse_encoder)\n",
    "sparse_autoencoder.add(sparse_decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "sparse_autoencoder.fit(x_train_flatten, x_train_flatten, epochs=25, batch_size=256,validation_data=(x_test_flatten, x_test_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say on the loss function compared with the previous model?\n",
    "\n",
    "**Exercise**  : Check that the encoded images obtained with the sparse autoencoder are indeed sparser than the ones obtained by the first autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/compare_sparsity_encoded_imgs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : Compare the decoded images obtained by the first and the sparse model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/compare_sparsity_decoded_imgs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we have seen very simple autoencoders where both encoder and decoder parts are composed of a single layer. They both can be composed of more layers (deep autoencoder) and with differents types of layers.\n",
    "\n",
    "As seen in the previous TP, convolutional layers are the best layers to use when dealing with images. \n",
    "\n",
    "**Exercise** : Implement a convolutional Autoencoder with the following architecture: \n",
    "\n",
    "`Encoder`\n",
    "* A 2d convolutional layer, 16 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "* A 2d convolutial layer, 8 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "* A 2d convolutial layer, 8 filters of size 3x3\n",
    "* A 2Dmaxpooling layer with filters of size 2x2\n",
    "\n",
    "`Decoder`\n",
    "* A 2d convolutional layer, 8 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 8 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 16 filters of size 3x3\n",
    "* A 2Dupsampling layer with filters of size 2x2\n",
    "* A 2d convolutional layer, 1 filters of size 3x3, with SIGMOID activation\n",
    "\n",
    "\n",
    "*All padding are `SAME` padding and all convolutional activation function but last are `RELU`*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/convolutional_autoencoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder = km.Sequential(name=\"ConvAutoencoderModel\")\n",
    "conv_autoencoder.add(conv_encoder)\n",
    "conv_autoencoder.add(conv_decoder)\n",
    "conv_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "conv_autoencoder.fit(x_train_conv, x_train_conv, epochs=10, batch_size=256, validation_data=(x_test_conv, x_test_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder.evaluate(x_train_conv, x_train_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = conv_encoder.predict(x_test_conv)\n",
    "decoded_imgs = conv_autoencoder.predict(x_test_conv)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to build a convolutional autoencoder. \n",
    "\n",
    "We will now see how it can be used to solve a denoising problem. \n",
    "\n",
    "We first create fake noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train_conv + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train_conv.shape) \n",
    "x_test_noisy = x_test_conv + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test_conv.shape) \n",
    "\n",
    "# Value greater than 1 are set to 1 and value lower than 0 are set to zero\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the noise we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # noisy data\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : Now let's train the same convolutional model that we built above. But let's train this model with noisy data as an input and the original data as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_denoise_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we pass the noisy test data into the trained autoencorder in order to denoise this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_denoised = conv_autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of the denoised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # noisy data\n",
    "    ax = plt.subplot(3, n, i + n+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # denoised data\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(x_test_denoised[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : Play with different architectures to decrease loss function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
