{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wikistat/High-Dimensional-Deep-Learning/blob/master/AutoEncoder/VariationalAutoEncoder_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files & Data (Google Colab)\n",
    "\n",
    "If you're running this notebook on Google colab, you do not have access to the `solutions` folder you get by cloning the repository locally. \n",
    "\n",
    "The following lines will allow you to build the folders and the files you need for this TP.\n",
    "\n",
    "**WARNING 1** Do not run this line localy.\n",
    "**WARNING 2** The magic command `%load` does not work work on google colab, you will have to copy-paste the solution on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir image\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_decoder.png\n",
    "! wget . https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/vae_mlp_vae.png\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_2.svg\n",
    "! wget image https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/image/vae_3.svg\n",
    "! mkdir solutions\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_decoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/compare_sparsity_encoded_imgs.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/convolutional_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoded_images_both_method.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/decoder_vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/generate_single_sample.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/simple_autoencoder.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/train_outlier_vae.py\n",
    "! wget solutions https://github.com/wikistat/High-Dimensional-Deep-Learning/raw/master/AutoEncoder/solutions/error_distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational autoencoder is an autoencoder that learns a latent variable model for its input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a simple Variational Auto Encoder\n",
    "* Use Variational Auto Encoder for Number Generation \n",
    "* Use Variational Auto Encoder To anomaly detection\n",
    "* Write a Convolutional Variational Auto Encoder\n",
    "* Use the Keras Model APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.losses as kloss\n",
    "import tensorflow.keras.regularizers as kr\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "input_dim = np.prod(x_train.shape[1:])\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "x_train = x_train.reshape((n_train, input_dim))\n",
    "x_test = x_test.reshape((n_test, input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous TP on image classification of the autoencoder notebook we have used the `Sequential` method to build model.\n",
    "\n",
    "Sequential Method have limits when the architecture we want is not *linear* or when we want to build a layer on top on two different entries.\n",
    "\n",
    "The `Model` API can sometimes be less intuitive but is much more flexible than the `Sequential` method. We will use it all along this TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## A simple Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "n_input = 784\n",
    "batch_size=100\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build the encoder part. <br>\n",
    "It is first composed of  a `Dense` layer with 512 neurons. <br>\n",
    "Two `Dense` layers are then added on **top of the same layer**. These two layers will produce the two variables *z_mean* and  *z_log_var* in the latent space.\n",
    "\n",
    "Note that we define each layer as a function of an input which is the output of the layer it follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "inputs = kl.Input(shape=(784,), name='encoder_input')\n",
    "# Dense layer from input layer\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "# Two dense layer that takes input from the same layer x\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ q(z/x) \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "<img src=\"image/vae_3.svg\" width=\"600px\" />\n",
    "\n",
    "\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ q(z/x) = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x))$ instead of $\\sigma_z(x)$. <br>\n",
    "Taking the exponential of $log(\\sigma^2_z(x)$ ensures the positivity of the standard deviation from the raw output of the network.\n",
    "\n",
    "\n",
    "Let's first define a function that takes as an input the output of the `Z_mean`, and `Z_log_var` previous layer and generate a sample from this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a keras layer from this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have defined all the layers we need to build the encoder part of the vae. <br> \n",
    "We now define the model, with the `Model`method. For that we just have to specify the input layer and the output we want (here, it's the latent variable z). The model is then build automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = km.Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "#ku.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder \n",
    "\n",
    "The decoder takes as an input the vector z (which is a sample of the latent distribution define by the encoder). \n",
    "It is then composed of 2 Dense layers with the following caracteristics : \n",
    "\n",
    "* 512 neurons, relu activation\n",
    "* 784 neurons (input_shape), sigmoid activation\n",
    "\n",
    "**Exercise** build this simple decoder model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/decoder_vae.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vae\n",
    "\n",
    "We now associate the encoder and the decoder to define our Variational Autoencoder.\n",
    "\n",
    "**Exercise** build this VAE model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement now the vae loss function  as described in the course\n",
    "\n",
    "$$VAE_{loss} = l(x,\\hat{x}) + KL(q(z/x),p(z))$$\n",
    "\n",
    "$l$ can be any loss function betwen the original image $x$ and the reconstructed image $\\hat{x}$. Here we use the binary crossentropy. \n",
    "\n",
    "\n",
    "$$ q(z/x) \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)), $$\n",
    "as described below. $p(z)$ is the latent distribution. The easiest choice  is  to take $p(z)\\sim \\mathcal{N}(0,1)$.\n",
    "\n",
    "\n",
    "**We first use the following result, that you can check :** \n",
    "\n",
    "If $P \\sim \\mathcal{N}_d(\\mu_p, \\Sigma_p) $ and $Q \\sim \\mathcal{N}_d(\\mu_q, \\Sigma_q) $, then \n",
    "$$\n",
    "KL(Q || P) = \\frac{1}{2}\\left[\\log\\frac{|\\Sigma_p|}{|\\Sigma_q|} - d + \\text{tr} \\{ \\Sigma_p^{-1}\\Sigma_q \\} + (\\mu_p - \\mu_q)^T \\Sigma_p^{-1}(\\mu_p - \\mu_q)\\right].\n",
    "$$\n",
    "\n",
    "In our case, $p(z) \\sim \\mathcal{N}_2(0,  I_2) $ and $ q(z/x) \\sim \\mathcal{N}_2(\\mu_z(x),\\sigma_z(x)) $. Hence, we have\n",
    "\n",
    "$\n",
    "KL(q(z/x) || p(z)) = \\frac{1}{2}\\left[-\\log|\\sigma_z(x)| - d + \\text{tr} \\{\\sigma_z(x) \\} +\\mu_z(x)^T \\mu_z(x)\\right].\n",
    "$\n",
    "\n",
    "which can be computed as : \n",
    "\n",
    "$KL(q(z/x) || p(z)) = \\frac{1}{2} \\, \\sum_{j=1}^2 \\left( \\sigma_{z,j}(x) + \\mu_{z,j}^2(x) - 1 - \\log \\sigma_{z,j}(x) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = kloss.binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "                epochs=40,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display images result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae.predict(x_test, batch_size= batch_size)\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for i in range(10):\n",
    "    x_test_encoded_i = x_test_encoded[y_test==i]\n",
    "    plt.scatter(x_test_encoded_i[:, 0], x_test_encoded_i[:, 1], label=i)\n",
    "ax.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Generate a image number from two random latent variables using the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/generate_single_sample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View of VAE Manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "In this part we'll see how variational autoencoder can be used to anomaly detections.\n",
    "\n",
    "We will consider that 9 images are outliers. \n",
    "\n",
    "We will generate four datasets from both train and test dataset, train and test without 9 images and train and test with only 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_i = 9\n",
    "x_train_normal = x_train[y_train!=outlier_i]\n",
    "n_train = x_train_normal.shape[0]-x_train_normal.shape[0]%100\n",
    "x_train_normal = x_train_normal[:n_train]\n",
    "x_test_normal =  x_test[y_test!=outlier_i]\n",
    "n_test = x_test_normal.shape[0]-x_test_normal.shape[0]%100\n",
    "x_test_normal = x_test_normal[:n_test]\n",
    "\n",
    "x_train_outliers = x_train[y_train==outlier_i]\n",
    "n_train = x_train_outliers.shape[0]-x_train_outliers.shape[0]%100\n",
    "x_train_outliers = x_train_outliers[:n_train]\n",
    "x_test_outliers =  x_test[y_test==outlier_i]\n",
    "n_test = x_test_outliers.shape[0]-x_test_outliers.shape[0]%100\n",
    "x_test_outliers = x_test_outliers[:n_test]\n",
    "\n",
    "x_train_normal.shape, x_train_outliers.shape, x_test_normal.shape, x_test_outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exervise** Build a VAE as we did above on this notebook and learn weights only on train dataset without 9 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/train_outlier_vae.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display decoded image\n",
    "\n",
    "Let's now try to use our VAE on test dataset with both known numbers (0 to 8) and with outliers (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_normal, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_normal[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae_ad.predict(x_test_outliers, batch_size=batch_size)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test_outliers[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : What can you say about the decoded images in both cases? Is it normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution\n",
    "\n",
    "To evaluate how the detection of 9 images will work, let us check the distribution of the different l2 errors between the original image and their reconstructed image for three types if images:\n",
    "\n",
    "* Images of know number (0 to 8)\n",
    "* Images of outlier (9)\n",
    "* Completly randomly generated images\n",
    "\n",
    "**Exercise** Generate these distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/error_distribution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sb.distplot(error_normal, ax=ax, label=\"Normal\")\n",
    "sb.distplot(error_outliers, ax=ax, label=\"Outliers\")\n",
    "sb.distplot(error_random , ax=ax, label=\"Random\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the error reconstruction of the different cases? What does it say about the performance of VAE to detect anomalies ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "**Exercise** You've seen how to build VAE and how to use it to generate new images and to detect anomalies. The VAE used so far only use Dense layer. \n",
    "\n",
    "Use CNN layers to build a convolutional VAE and test the different applications (generate images and detect anomalies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
