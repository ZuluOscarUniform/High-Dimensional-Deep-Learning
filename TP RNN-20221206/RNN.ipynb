{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50eb139-5964-4b5a-af0e-e4b69e1560aa",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "_Sentiment analysis through Recurrent Neural Networks_\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial, we are interested in the problem of sentiment analysis. In the first part, we will build a recurrent network on a toy dataset from scratch to determine if a sentence is positive or negative. In a second step, using the [`Keras`](https://keras.io/) API, we will build a network able to determine if a movie review is positive or negative.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef5871b-799b-40e5-a2b0-863bfcf6e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7b446-678c-45fe-80e4-a49c8448f3e2",
   "metadata": {},
   "source": [
    "---\n",
    "# PART I: RNN from Scratch\n",
    "\n",
    "In order to understand recurrent networks in more detail, our first example will be implementing a network from scratch. The network will perform a (simple) sentiment analysis task, namely determining whether a given text string is positive or negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a36b5-ac50-4a26-9b14-e7a61017eac8",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "The commands below allow displaying some samples of our toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73ff428-67f1-4538-89e2-e254c86e0051",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_data, test_data\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mlist\u001b[39m(train_data\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m15\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems())\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from data import train_data, test_data\n",
    "\n",
    "list(train_data.items())[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170f3e9-18b4-421d-a112-fb06cf127bf1",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "In order to visualize quickly the labels, we want display in _green_ the <span style=\"color:green\">positive sentences</span>, and in _red_ the <span style=\"color:orangered\">negative sentences</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f371d9b-de65-4f33-9a2c-2f482ccaa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c949fe-5a45-461c-99f7-8baba3fc7528",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Using the command `Fore.COLOR` of the package [`colorama`](https://pypi.org/project/colorama/), realize such a function.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f973db-c41a-47b7-909e-7e3b7e880778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore\n",
    "\n",
    "def coloredSentences(sentences, out=15):\n",
    "    \"\"\"\n",
    "    Display in green the positive sentences, and in red the negative sentences\n",
    "    - sentences is a dict\n",
    "        - sentences.keys() are the sentences to display\n",
    "        - sentences.values() are booleans that encode the sentiment\n",
    "    - out is an integer indicating the maximum number of sentences to display\n",
    "    \"\"\"\n",
    "    n = min(len(sentences),15)\n",
    "    for key,value in list(sentences.items())[:n]:\n",
    "        if value:\n",
    "            print(Fore.GREEN + key)\n",
    "        else:\n",
    "            print(Fore.RED + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac11a88-34b0-4c1c-aa8b-9873947646e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/coloredSentences.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983c0401-f9c9-44ab-9ef7-5b4f7bce72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mgood\n",
      "\u001b[31mbad\n",
      "\u001b[32mhappy\n",
      "\u001b[31msad\n",
      "\u001b[31mnot good\n",
      "\u001b[32mnot bad\n",
      "\u001b[31mnot happy\n",
      "\u001b[32mnot sad\n",
      "\u001b[32mvery good\n",
      "\u001b[31mvery bad\n",
      "\u001b[32mvery happy\n",
      "\u001b[31mvery sad\n",
      "\u001b[32mi am happy\n",
      "\u001b[32mthis is good\n",
      "\u001b[31mi am bad\n"
     ]
    }
   ],
   "source": [
    "coloredSentences(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bcbe8-1af8-4528-8f3c-52851ed1be38",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "The datasets consists of two $\\texttt{dictionaries}$. Before trying to classify these sentences, we will build a vocabulary of all of all words that exist in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f59b2-9f2c-49cc-a18c-7226ab2b39d9",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** How many different words are in our vocabulary?</span>\n",
    "\n",
    "To answer this question, start by building a **vocabulary**, _i.e._ a $\\texttt{list}$ containing all the words used in the dataset. _Each word should occur only once_.\n",
    "\n",
    "<!-- 18 unique words found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93d8981f-29b0-46e7-9ba3-ab5018983886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 unique words found\n",
      "['all', 'not', 'earlier', 'and', 'at', 'bad', 'was', 'or', 'very', 'happy', 'i', 'this', 'good', 'am', 'sad', 'right', 'now', 'is']\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "string_all = \" \".join(train_data.keys())\n",
    "vocab = list(set(string_all.split()))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('%d unique words found' % vocab_size)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ea5e36-da35-4d9a-a6a7-789c9646cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/vocab_size.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbee304-e47d-4726-bfa6-f09d81b400fd",
   "metadata": {},
   "source": [
    "### Word Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c1bc7-928c-44c9-8169-1b1b591ecd59",
   "metadata": {},
   "source": [
    "A neural network cannot take strings as input. So we have to encode these sentences in a format understandable by a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215ad08-6dd8-4f4e-9fbd-8534963c45f1",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Assign an integer index to represent each word of the vocab</span>\n",
    "\n",
    "To do that, construct two $\\texttt{dictionaries}$ allowing to translate words into integer indices, and vice versa :\n",
    "\n",
    "* $\\texttt{word_to_idx}$ has for keys the words of the vocabulary; and for value an integer index, the order in which the words appear in the vocabulary for example.\n",
    "* $\\texttt{word_to_idx}$ performs the opposite translation: its keys are the integer indices while its values are the associated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d068ab-58fe-4c73-87e4-a8ff51610c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "all\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "word_to_idx = {vocab[i]:i for i in range(vocab_size)}\n",
    "idx_to_word = {i:vocab[i] for i in range(vocab_size)}\n",
    "\n",
    "print(word_to_idx['good'])\n",
    "print(idx_to_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955a2cb-3d3a-4dd4-b2ef-2a7e5962ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/decode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a93da-4411-446f-bfce-93bf4f47fd51",
   "metadata": {},
   "source": [
    "This way of encoding words works quite well. However, it has the disadvantage of introducing a preferential but meaningless order in how words are processed. Since the vocabulary size is reasonable, we will use a one-shot encoding instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5709bea-e8eb-44e4-ad4a-ec4cdeeb3589",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a function $\\texttt{createInputs}$ that performs one-hot encoding</span>\n",
    "\n",
    "This function will return a $\\texttt{list}$ of the one-hot encodings of each word that compose the input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f355dd2-3d90-447e-8452-fad744ddbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def createInputs(text):\n",
    "    '''\n",
    "    Returns an array of one-hot vectors representing the words in the input text string.\n",
    "    - text is a string\n",
    "    - Each one-hot vector has shape (vocab_size, 1)\n",
    "    '''\n",
    "    words = text.split()\n",
    "    out = np.zeros((len(words),vocab_size))\n",
    "    for i,w in enumerate(words):\n",
    "        out[i,word_to_idx[w]] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce782e44-3e95-4e8d-ad66-c1fc8d750c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/createInputs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c99eedd1-887e-485f-a948-db7b6db5d11d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "13\n",
      "8\n",
      "12\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(createInputs('i am very good'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa1677-ef5f-4137-9b0e-2ea557497232",
   "metadata": {},
   "source": [
    "## The Forward Phase\n",
    "\n",
    "In this part, we will build the simplest possible recursive network. To do so, we will create an $\\texttt{RNN}$ class that we will update as we build it. We want to classify a textual data. To do so, we will use a many-to-one network, as shown in the figure below.\n",
    "\n",
    "<img src=\"img/many-to-one.png\" width=250>\n",
    "\n",
    "Let a sentence $x=(x_0,\\ldots,x_n)$, its label $y$, and let $h=(h_0,\\ldots,h_n)$ be the corresponding hidden state. We give ourselves three weight matrices, $W_{xh}$, $W_{hh}$ and $W_{hy}$, and two bias vectors, $b_h$ and $b_y$, so that, for any $t\\in[\\![0,n]\\!]$:\n",
    "\n",
    "$$ \\left\\{\\begin{aligned}\n",
    "    h_t &= \\tanh\\left( W_{xh}x_t + W_{hh}h_{t-1} + b_h \\right) \\\\\n",
    "    y &= W_{hy}h_n + b_y\n",
    "\\end{aligned}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b536e-0edd-4b0f-9bcf-a3c9a8730cc6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What is the dimension of the different weight matrices and bias vectors?</span>\n",
    "\n",
    "You can freely use the following notations:\n",
    "* $n_h$ denotes the $\\texttt{hidden_size}$, _i.e._ the size oh the hidden vectors $h_t$;\n",
    "* $n_x$ denotes the $\\texttt{input_size}$, _i.e._ the size of the inputs $x_t$;\n",
    "* $n_y$ denotes the $\\texttt{output_size}$, _i.e._ the size of the output $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81fb7e-25ad-409e-abe7-f69441a3b117",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "* $W_{xh} : n_h,n_x$\n",
    "* $W_{hh} : n_h,n_h$\n",
    "* $W_{hy} : n_y,n_h$\n",
    "* $b_{h} : n_h$\n",
    "* $b_{y} : n_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245a61a-05d5-4608-9a7b-d03bb71bec7c",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "<!-- **Solution**:\n",
    "* $W_{xh}\\in\\mathcal{M}_{n_h,n_x}(\\mathbb{R})$\n",
    "* $W_{hh}\\in\\mathcal{M}_{n_h,n_h}(\\mathbb{R})$\n",
    "* $W_{hy}\\in\\mathcal{M}_{n_y,n_h}(\\mathbb{R})$\n",
    "* $b_h\\in\\mathcal{M}_{n_h,1}(\\mathbb{R})$\n",
    "* $b_y\\in\\mathcal{M}_{n_y,1}(\\mathbb{R})$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eca9c7-cca2-4147-85e9-a855758a7258",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Initialize the weight matrices and bias vectors. Realize the forward pass.</span>\n",
    "\n",
    "* The weights are initialized from the standard normal distribution, dividing by 1000 to reduce the initial variance. The biases are initialized to zero. \n",
    "* For the forward pass, first initialize the hidden state $h_0$ to zero, then perform each step of the RNN.\n",
    "\n",
    "**Note:** As said, dividing by 1000 the weights reduce the initial variance. This is not the best way to initialize weights, but it's simple and works for this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "04741a3f-df11-4889-b324-c25ae96bd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        self.nh = hidden_size\n",
    "        self.nx = input_size\n",
    "        self.ny = output_size\n",
    "        \n",
    "        # Weights\n",
    "        self.Whh = np.random.normal(size=(hidden_size,hidden_size))/1000\n",
    "        self.Wxh = np.random.normal(size=(hidden_size,input_size))/1000\n",
    "        self.Why = np.random.normal(size=(output_size,hidden_size))/1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros(hidden_size)\n",
    "        self.by = np.zeros(output_size)\n",
    "        \n",
    "    # ----- #\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        N = np.shape(inputs)[0]\n",
    "        h = np.zeros((N,self.nh))\n",
    "        x = inputs\n",
    "        \n",
    "        h[0,:] = np.tanh(self.Wxh.dot(x[0,:]) + self.bh)\n",
    "        for t in range(1,N):\n",
    "            h[t,:] = np.tanh(self.Wxh.dot(x[t,:]) + self.Whh.dot(h[t-1]) + self.bh)\n",
    "        \n",
    "        y = self.Why.dot(h[-1,:]) + self.by\n",
    "\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73c0f0-57c8-457a-963e-f7b00f85cdbb",
   "metadata": {},
   "source": [
    "**Remark:** Before looking at the solution, you can test your $\\texttt{RNN}$ class by passing any input into the network. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b462aae-40a4-4ecd-bb96-7cac866a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/RNN_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134b449-9af4-4e0f-b69a-2f2109e85e63",
   "metadata": {},
   "source": [
    "The binary classification is performed using the $\\texttt{softmax}$ function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e382b7-2c91-400d-bae9-d5c4a8c5c21f",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Implement the softmax function.</span>\n",
    "\n",
    "As a reminder, for $x=(x_0,\\ldots,x_n)$ and $i_0\\in[\\![0,n]\\!]$, $~softmax(x_{i_0}) = \\frac{e^{x_{i_0}}}{\\sum_i e^{x_i}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d5559d7f-1ce8-4bf6-9b9f-1fe7493cd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e = np.exp(x)\n",
    "    return e/e.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "445066ad-64e0-4d8f-8c63-527eb373e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/softmax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b532e5f-8b5f-4729-ade4-fdfb935cb291",
   "metadata": {},
   "source": [
    "To ensure that we have not made an implementation error, we can pass a sentence from the training set through the network. Since the network has not yet been trained, we should find that this sentence is as likely to be positive as negative, i.e., a probability vector approximately equal to [0.5, 0.5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2596c28e-0591-480c-9560-74ef4cc1864b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (64,64) into shape (64,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m rnn \u001b[38;5;241m=\u001b[39m RNN(vocab_size, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m createInputs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi am very good\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(out)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m probs \u001b[38;5;241m=\u001b[39m softmax(out)\n",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((N,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnh))\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 31\u001b[0m h[\u001b[38;5;241m0\u001b[39m,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWxh\u001b[38;5;241m.\u001b[39mdot(x[\u001b[38;5;241m0\u001b[39m,:]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbh)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,N):\n\u001b[1;32m     33\u001b[0m     h[t,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWxh\u001b[38;5;241m.\u001b[39mdot(x[t,:]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWhh\u001b[38;5;241m.\u001b[39mdot(h[t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbh)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (64,64) into shape (64,)"
     ]
    }
   ],
   "source": [
    "# Initialize the RNN\n",
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "inputs = createInputs('i am very good')\n",
    "out, _ = rnn.forward(inputs)\n",
    "# print(out)\n",
    "\n",
    "probs = softmax(out)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4653e2b-af3b-434b-a655-dea00d664948",
   "metadata": {},
   "source": [
    "## The Backward Phase\n",
    "\n",
    "Lets move on to training. To this end, we first need a loss function. We will use the cross-entropy loss, which is often associated with the $softmax$ function. Let $\\sigma$ denotes the $softmax$ function and $y_c$ be the _correct_ class. Then:\n",
    "\n",
    "$$ \\mathcal{L} = \\mathcal{L}(x,y;W_{xh},W_{hh},W_{hy},b_h,b_y) = -\\log(p_c) \\qquad\\text{where}\\qquad p_c = \\sigma(y_c) \\,. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d002d-6db4-4662-b12f-d7dc8cf183a6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Prove that for all $i\\in\\{0,1\\}$, $\\displaystyle\\quad\\frac{\\partial\\mathcal{L}}{\\partial y_i} = \\left\\{\\begin{aligned}\n",
    "    &p_i=\\sigma(y_i) & \\text{if}\\quad c\\neq i\\\\\n",
    "    &p_c-1=\\sigma(y_c)-1 & \\text{if}\\quad c=i\n",
    "\\end{aligned}\\right. $</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b733e7d-b7e9-4edd-ba36-718b24ac3c47",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d048a3-5b1a-4b87-bca1-490f2289ab49",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "<!-- **Solution**: $\\mathcal{L}(y_i)=-\\log(\\sigma(y_c))$. Hence, $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial y_i}=-\\frac1{\\sigma(y_c)}\\times\\frac{\\partial\\sigma}{\\partial y_i}$.\n",
    "* If $i\\neq c$,\n",
    "$$ \\frac{\\partial\\sigma}{\\partial y_i} = \\frac{ -e^{y_c}\\times e^{y_i} }{ \\left(\\sum_ke^{y_k}\\right)^2 }\n",
    "    = \\frac{-e^{y_c}}{\\sum_ke^{y_k}}\\times\\frac{e^{y_i}}{\\sum_ke^{y_k}} = -\\sigma(y_c)\\times\\sigma(y_i) \n",
    "    \\qquad\\text{and}\\qquad\n",
    "   \\frac{\\partial\\mathcal{L}}{\\partial y_i} = -\\frac{-\\sigma(y_c)\\times\\sigma(y_i)}{\\sigma(y_c)} = \\sigma(y_i)=p_i \\,. $$\n",
    "\n",
    "* Else,\n",
    "$$ \\frac{\\partial\\sigma}{\\partial y_c} = \\frac{ e^{y_c}\\left(\\sum_ke^{y_k}\\right)-e^{y_c}\\times e^{y_c} }{ \\left(\\sum_ke^{y_k}\\right)^2 }\n",
    "    = \\frac{e^{y_c}}{\\sum_ke^{y_k}}-\\left(\\frac{e^{y_c}}{\\sum_ke^{y_k}}\\right)^2 = \\sigma(y_c)-\\sigma(y_c)^2 \n",
    "    \\qquad\\text{and}\\qquad\n",
    "   \\frac{\\partial\\mathcal{L}}{\\partial y_c} = -\\frac{\\sigma(y_c)-\\sigma(y_c)^2}{\\sigma(y_c)} = \\sigma(y_c)-1=p_c-1 \\,. $$-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaaeab7-29f1-4e11-9904-b443aea5a96a",
   "metadata": {},
   "source": [
    "Let us modify the $\\texttt{forward}$ function in the $\\texttt{RNN}$ class to cache the hidden states $h$ and the inputs $x$, which we will need for computing the gradients in the back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84b1fdde-aec5-45d9-a7ac-8e7c820e91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        self.nh = hidden_size\n",
    "        self.nx = input_size\n",
    "        self.ny = output_size\n",
    "        \n",
    "        # Weights\n",
    "        self.Whh = np.random.normal(size=(hidden_size,hidden_size))/1000\n",
    "        self.Wxh = np.random.normal(size=(hidden_size,input_size))/1000\n",
    "        self.Why = np.random.normal(size=(output_size,hidden_size))/1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros(hidden_size)\n",
    "        self.by = np.zeros(output_size)\n",
    "    \n",
    "    # ----- #\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        N = np.shape(inputs)[0]\n",
    "        h = np.zeros((N,self.nh))\n",
    "        x = inputs\n",
    "                \n",
    "        h[0,:] = np.tanh(self.Wxh.dot(x[0,:]) + self.bh)\n",
    "        for t in range(1,N):\n",
    "            h[t,:] = np.tanh(self.Wxh.dot(x[t,:]) + self.Whh.dot(h[t-1]) + self.bh)\n",
    "        \n",
    "        y = self.Why.dot(h[-1,:]) + self.by\n",
    "        \n",
    "        self.hs = h\n",
    "        return y, h[-1,:]\n",
    "    \n",
    "#     # ----- #\n",
    "    \n",
    "    def backprop(self, d_y, learn_rate=2e-2):\n",
    "        '''    \n",
    "        Perform a backward pass of the RNN.    \n",
    "        - d_y (dL/dy) has shape (output_size, 1).    \n",
    "        - learn_rate is a float.    \n",
    "        '''    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc4fff-8b21-436a-88b9-ea81ab890754",
   "metadata": {},
   "source": [
    "Therefore, given a backward pass, we can train the RNN using the following loop on all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a16f419-b2f2-4d6b-bb8d-cc585c2ecec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49999901  0.49999901]\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "# Loop over each training example\n",
    "for x, y in train_data.items():\n",
    "    inputs = createInputs(x)\n",
    "    target = int(y)\n",
    "\n",
    "    # Forward\n",
    "    out, _ = rnn.forward(inputs)\n",
    "    probs = softmax(out)\n",
    "\n",
    "    # Build dL/dy\n",
    "    d_L_d_y = probs\n",
    "    d_L_d_y[target] -= 1\n",
    "    \n",
    "    # Backward\n",
    "    rnn.backprop(d_L_d_y)\n",
    "    \n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f23f52-7393-437a-baf6-db2878ec7564",
   "metadata": {},
   "source": [
    "### Gradient Computation\n",
    "\n",
    "It is then sufficient to backpropagate the gradient to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcff619-c716-4da1-a492-0836e2ac198c",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What are the parameters of the model to optimize?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf18f38-e142-4b00-8598-8638eec82f5a",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c2f99-ef43-4a0d-beca-ebad89fc65c3",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "<!-- **Solution**: \n",
    "* The weights matrices $W_{xh}\\in\\mathcal{M}_{n_h,n_x}(\\mathbb{R})$, $W_{hh}\\in\\mathcal{M}_{n_h,n_h}(\\mathbb{R})$ and $W_{hy}\\in\\mathcal{M}_{n_y,n_h}(\\mathbb{R})$\n",
    "* The bias vectors $b_h\\in\\mathcal{M}_{n_h,1}(\\mathbb{R})$ and $b_y\\in\\mathcal{M}_{n_y,1}(\\mathbb{R})$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf612ed-db24-47dc-b9b7-971b260416c0",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** Compute the gradients $\\frac{\\partial\\mathcal{L}}{\\partial W_{hy}}$ and $\\frac{\\partial\\mathcal{L}}{\\partial b_y}$.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e593d8-3894-48f9-ad8f-192d7d692ff9",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601a37f-1d4c-4a43-b3e9-84fc63a55526",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "<!-- **Solution**: Recall that $y=W_{hy}h_n+b_y$, where $h_n$ is the final hidden state. Then:\n",
    "* $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial W_{hy}} \n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y}\\times\\frac{\\partial y}{\\partial W_{hy}}\n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y} h_n \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial b_y} \n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y}\\times\\frac{\\partial y}{\\partial b_y}\n",
    "    = \\frac{\\partial\\mathcal{L}}{\\partial y} \\,.$\n",
    "    \n",
    "_Note:_ Beware of the dimensions of these objects! These are not partial derivatives in $\\mathbb{R}$... -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94707e-9d88-4849-b782-d0f10f37edfd",
   "metadata": {},
   "source": [
    "Finally, we need the gradients for $W_{xh}$, $W_{hh}$, and $b_h$, which are used every step during the RNN. For example, for $W_{xh}$, we have \n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial W_{xh}} = \\frac{\\partial\\mathcal{L}}{\\partial y} \\sum_{t=0}^n \\frac{\\partial y}{\\partial h_t}\\frac{\\partial h_t}{\\partial W_{xh}} $$\n",
    "because changing $W_{xh}$ affects every $h_t$, which all affect $y$ and ultimately $\\mathcal{L}$. In order to fully calculate the gradient of $W_{xh}$, we will need to backpropagate through all time-steps, which is known as Backpropagation Through Time (BPTT).\n",
    "\n",
    "<img src=\"img/bptt.png\" width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae05a60-f044-4da2-8fa9-543b380d337c",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Exercise:** At a given time step $t$, compute $\\frac{\\partial h_t}{\\partial W_{xh}}$, $\\frac{\\partial h_t}{\\partial W_{hh}}$ and $\\frac{\\partial h_t}{\\partial b_h}$.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eb5fa-99f7-443e-bfa5-3575478d2359",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd5b9a-c5d6-425b-93f8-fe3d889f172a",
   "metadata": {},
   "source": [
    "<span style=\"color:teal \">[Solution]</span>\n",
    "\n",
    "**Solution**: Recall that $h_t=\\tanh\\left( W_{xh}x_t + W_{hh}h_{t-1} + b_h \\right)$ and that $\\tanh^\\prime(x)=1-\\tanh^2(x)$. Then:\n",
    "\n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial W_{xh}} = (1-h_t^2)\\,x_t \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial W_{hh}} = (1-h_t^2)\\,h_{t-1} \\,;$\n",
    "    \n",
    "* $\\displaystyle\\frac{\\partial h_t}{\\partial b_h} = (1-h_t^2) \\,.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a41d3-a841-46a2-8d96-a3e7f2a38cc9",
   "metadata": {},
   "source": [
    "The last thing we need is $\\frac{\\partial y}{\\partial h_t}$. We can calculate it recursively:\n",
    "\n",
    "$$ \\forall t\\in[\\![0,n-1]\\!]\\,,\\quad  \\dfrac{\\partial y}{\\partial h_t} \n",
    "    = \\dfrac{\\partial y}{\\partial h_{t+1}}\\times\\dfrac{\\partial h_{t+1}}{\\partial h_t} \n",
    "    = \\dfrac{\\partial y}{\\partial h_{t+1}}\\,(1-h_t^2)\\,W_{hh}\n",
    "    \\qquad\\text{and}\\qquad \n",
    "    \\dfrac{\\partial y}{\\partial h_n}=W_{hy} \\,.$$\n",
    "    \n",
    "_Note:_ The recursion is _backward!_ We will implement BPTT starting from the last hidden state and working backwards, so we will already have $\\frac{\\partial y}{\\partial h_{t+1}}$ by the time we want to calculate $\\frac{\\partial y}{\\partial h_t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0611406-c339-481a-ae5b-53dbc0be775c",
   "metadata": {},
   "source": [
    "#### Back-Propagation Through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95254000-416e-452c-a205-322c781a80eb",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Using the previous gradients computations, implement the back-propagation through time.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61da59f-3b87-4f20-a2d4-8943614283d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "# class RNN:\n",
    "#     # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "#     def __init__(self, input_size, output_size, hidden_size=64):\n",
    "#         self.nh = hidden_size\n",
    "#         self.nx = input_size\n",
    "#         self.ny = output_size\n",
    "        \n",
    "#         # Weights\n",
    "#         self.Whh = np.random.normal(size=(hidden_size,hidden_size))/1000\n",
    "#         self.Wxh = np.random.normal(size=(hidden_size,input_size))/1000\n",
    "#         self.Why = np.random.normal(size=(output_size,hidden_size))/1000\n",
    "\n",
    "#         # Biases\n",
    "#         self.bh = np.zeros(hidden_size)\n",
    "#         self.by = np.zeros(output_size)\n",
    "    \n",
    "#     # ----- #\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         '''\n",
    "#         Perform a forward pass of the RNN using the given inputs.\n",
    "#         Returns the final output and hidden state.\n",
    "#         - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "#         '''\n",
    "#         N = np.shape(inputs)[0]\n",
    "#         h = np.zeros((N,self.nh))\n",
    "#         x = inputs\n",
    "    \n",
    "#         self.inputs = x\n",
    "        \n",
    "#         h[0,:] = np.tanh(self.Wxh.dot(x[0,:]) + self.bh)\n",
    "#         for t in range(1,N):\n",
    "#             h[t,:] = np.tanh(self.Wxh.dot(x[t,:]) + self.Whh.dot(h[t-1]) + self.bh)\n",
    "        \n",
    "#         y = self.Why.dot(h[-1,:]) + self.by\n",
    "        \n",
    "#         self.h = h\n",
    "#         return y, h[-1,:]\n",
    "    \n",
    "    \n",
    "#     # ----- #\n",
    "    \n",
    "#     def backprop(self, d_y, learn_rate=2e-2):\n",
    "#         '''    \n",
    "#         Perform A backward pass of the RNN.    \n",
    "#         - d_y (dL/dy) has shape (output_size, 1).    \n",
    "#         - learn_rate is a float.    \n",
    "#         '''    \n",
    "#         n = len(self.inputs)\n",
    "\n",
    "#         # Calculate dL/dWhy and dL/dby.\n",
    "#         d_Why = d_y.dot(self.h[-1,:].T)\n",
    "#         d_by = d_y\n",
    "        \n",
    "#         # Initialize dL/dWhh, dL/dWxh, and dL/dbh to zero.\n",
    "#         d_Whh = np.zeros((self.nh,self.nh))\n",
    "#         d_Wxh = np.zeros((self.nh,self.nx))\n",
    "#         d_bh = np.zeros((self.nh))\n",
    "\n",
    "#         # Calculate dL/dh for the last h.\n",
    "#         d_h = self.Why.T.dot(d_y)\n",
    "\n",
    "#         # Backpropagate through time.\n",
    "#         for t in reversed(range(n)):\n",
    "#             # An intermediate value: dL/dh * (1 - h^2)\n",
    "#             tmp = d_h * (1-self.h[t+1,:]**2)\n",
    "\n",
    "#             # dL/db = dL/dh * (1 - h^2)\n",
    "#             d_bh += tmp\n",
    "#             # dL/dWhh = dL/dh * (1 - h^2) * h_{t-1}\n",
    "#             d_Whh += tmp.dot(self.h[t,:].T)\n",
    "#             # dL/dWxh = dL/dh * (1 - h^2) * x\n",
    "#             d_Wxh += tmp.dot(self.inputs[t,:].T)\n",
    "#             # Next dL/dh = dL/dh * (1 - h^2) * Whh\n",
    "#             d_h = tmp.dot(self.Whh)\n",
    "            \n",
    "#         # Clip to prevent exploding gradients.\n",
    "#         for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n",
    "#             np.clip(d, -1, 1, out=d)\n",
    "            \n",
    "#         # Update weights and biases using gradient descent.\n",
    "#         self.Whh -= learn_rate*d_Whh\n",
    "#         self.Wxh -= learn_rate*d_Wxh\n",
    "#         self.Why -= learn_rate*d_Why\n",
    "#         self.bh -= learn_rate*d_bh\n",
    "#         self.by -= learn_rate*d_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e8da0ca-8352-4e1e-8ec2-9913816a59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/RNN_v2.py\n",
    "class RNN:\n",
    "    # A Vanilla Recurrent Neural Network.\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size=64):\n",
    "        # Weights\n",
    "        self.Whh = rd.randn(hidden_size, hidden_size) / 1000\n",
    "        self.Wxh = rd.randn(hidden_size, input_size) / 1000\n",
    "        self.Why = rd.randn(output_size, hidden_size) / 1000\n",
    "\n",
    "        # Biases\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Perform a forward pass of the RNN using the given inputs.\n",
    "        Returns the final output and hidden state.\n",
    "        - inputs is an array of one-hot vectors with shape (input_size, 1).\n",
    "        '''\n",
    "        h = np.zeros((self.Whh.shape[0], 1))\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.hs = { 0: h }\n",
    "        \n",
    "        # Perform each step of the RNN\n",
    "        for i, x in enumerate(inputs):\n",
    "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
    "            self.hs[i + 1] = h\n",
    "            \n",
    "        # Compute the output\n",
    "        y = self.Why.dot(h.T).T+ self.by\n",
    "        print(y.shape)\n",
    "        return y, h\n",
    "    \n",
    "    # ----- #\n",
    "    \n",
    "    def backprop(self, d_y, learn_rate=2e-2):\n",
    "        '''    \n",
    "        Perform a backward pass of the RNN.    \n",
    "        - d_y (dL/dy) has shape (output_size, 1).    \n",
    "        - learn_rate is a float.    \n",
    "        '''    \n",
    "        n = len(self.inputs)\n",
    "\n",
    "        # Calculate dL/dWhy and dL/dby.\n",
    "        d_Why = d_y @ self.hs[n].transpose()\n",
    "        d_by = d_y\n",
    "        \n",
    "        # Initialize dL/dWhh, dL/dWxh, and dL/dbh to zero.\n",
    "        d_Whh = np.zeros(self.Whh.shape)\n",
    "        d_Wxh = np.zeros(self.Wxh.shape)\n",
    "        d_bh = np.zeros(self.bh.shape)\n",
    "\n",
    "        # Calculate dL/dh for the last h.\n",
    "        print(d_y.shape,self.Why.shape)\n",
    "        d_h = self.Why.transpose() @ d_y\n",
    "        print(d_h.shape)\n",
    "\n",
    "        # Backpropagate through time.\n",
    "        for t in reversed(range(n)):\n",
    "            # An intermediate value: dL/dh * (1 - h^2)\n",
    "            tmp = (1 - self.hs[t+1]**2) * d_h\n",
    "            print(tmp.shape)\n",
    "            print(d_bh.shape)\n",
    "            # dL/db = dL/dh * (1 - h^2)\n",
    "            d_bh += tmp\n",
    "            # dL/dWhh = dL/dh * (1 - h^2) * h_{t-1}\n",
    "            d_Whh += tmp @ self.hs[t].transpose()\n",
    "            # dL/dWxh = dL/dh * (1 - h^2) * x\n",
    "            d_Wxh += tmp @ self.inputs[t].transpose()\n",
    "            # Next dL/dh = dL/dh * (1 - h^2) * Whh\n",
    "            d_h = self.Whh @ tmp\n",
    "            \n",
    "        # Clip to prevent exploding gradients.\n",
    "        for d in [d_Wxh, d_Whh, d_Why, d_bh, d_by]:\n",
    "            np.clip(d, -1, 1, out=d)\n",
    "            \n",
    "        # Update weights and biases using gradient descent.\n",
    "        self.Whh -= learn_rate * d_Whh\n",
    "        self.Wxh -= learn_rate * d_Wxh\n",
    "        self.Why -= learn_rate * d_Why\n",
    "        self.bh -= learn_rate * d_bh\n",
    "        self.by -= learn_rate * d_by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedbd00-7275-4403-990f-6fa1a2a55149",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edd547-6da6-4f91-a222-f889a1140af2",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a helper function to process data with the RNN.</span>\n",
    "\n",
    "To do this, you can refer to the various tests we have carried out previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d7b2ed5-59a0-482d-ad7f-a3636c63721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(data, backprop=True):\n",
    "    '''\n",
    "    Returns the RNN's loss and accuracy for the given data.\n",
    "    - data is a dictionary mapping text to True or False.\n",
    "    - backprop determines if the backward phase should be run.\n",
    "    '''\n",
    "    items = list(data.items())\n",
    "    random.shuffle(items)\n",
    "\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in items:\n",
    "        inputs = createInputs(x)\n",
    "        target = int(y)\n",
    "\n",
    "        # Forward\n",
    "        out, _ = rnn.forward(inputs)\n",
    "        probs = softmax(out)\n",
    "\n",
    "        # Calculate loss / accuracy\n",
    "        loss -= np.log(probs[target])\n",
    "        num_correct += int(np.argmax(probs) == target)\n",
    "\n",
    "        if backprop:\n",
    "            # Build dL/dy\n",
    "            d_L_d_y = probs\n",
    "            d_L_d_y[target] -= 1\n",
    "            \n",
    "            # Backward\n",
    "            rnn.backprop(d_L_d_y)\n",
    "\n",
    "    return loss/len(data), num_correct/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "33acc766-bb03-4d82-8d32-037621d9de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/processData.py\n",
    "def processData(data, backprop=True):\n",
    "    '''\n",
    "    Returns the RNN's loss and accuracy for the given data.\n",
    "    - data is a dictionary mapping text to True or False.\n",
    "    - backprop determines if the backward phase should be run.\n",
    "    '''\n",
    "    items = list(data.items())\n",
    "    random.shuffle(items)\n",
    "\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    for x, y in items:\n",
    "        inputs = createInputs(x)\n",
    "        target = int(y)\n",
    "\n",
    "        # Forward\n",
    "        out, _ = rnn.forward(inputs)\n",
    "        probs = softmax(out)\n",
    "\n",
    "        # Calculate loss / accuracy\n",
    "        loss -= np.log(probs[target])\n",
    "        num_correct += int(np.argmax(probs) == target)\n",
    "\n",
    "        if backprop:\n",
    "            # Build dL/dy\n",
    "            d_L_d_y = probs\n",
    "            d_L_d_y[target] -= 1\n",
    "\n",
    "            # Backward\n",
    "            rnn.backprop(d_L_d_y)\n",
    "\n",
    "    return loss/len(data), num_correct/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ce1e1-ea95-4543-84f1-17b798e5cc4b",
   "metadata": {},
   "source": [
    "Last, we can write the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "780f3764-56bc-4005-9772-34f25e1ddace",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (64,2) (2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [161]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mprocessData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[0;32mIn [160]\u001b[0m, in \u001b[0;36mprocessData\u001b[0;34m(data, backprop)\u001b[0m\n\u001b[1;32m     16\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m probs \u001b[38;5;241m=\u001b[39m softmax(out)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate loss / accuracy\u001b[39;00m\n",
      "Input \u001b[0;32mIn [158]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhs[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m h\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Compute the output\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, h\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (64,2) (2,1) "
     ]
    }
   ],
   "source": [
    "rnn = RNN(vocab_size, 2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    train_loss, train_acc = processData(train_data)\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print('--- Epoch %d' % (epoch + 1))\n",
    "        print('Train:\\tLoss %.3f | Accuracy: %.3f' % (train_loss, train_acc))\n",
    "\n",
    "        test_loss, test_acc = processData(test_data, backprop=False)\n",
    "        print('Test:\\tLoss %.3f | Accuracy: %.3f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5a81b-ad5d-492c-85eb-019037c79179",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Visualize the results of the training on the test data.</span>\n",
    "\n",
    "You will use the same color code as for the visualization of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186ecee-9f92-4604-afc6-e558175c55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f04e8-5a21-4d64-b3d6-f0beaffab2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/scratch/coloredResults.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994082-8f7d-4670-8228-81c138987c3f",
   "metadata": {},
   "source": [
    "# Part II: Study of the [IMDB](http://ai.stanford.edu/~amaas/data/sentiment/) Dataset\n",
    "\n",
    "<img src=\"img/imdb.png\" width=500>\n",
    "\n",
    "In this second part, we will train a classifier movie reviews in IMDB data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7a5d5a77-5e48-411a-900d-02a3a099f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1241d4-2b21-4681-8961-fe79735df19e",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d50de66b-11bb-489a-aaba-0199b2f8da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(start_char=1, oov_char=2, index_from=3)\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e757e60-06ff-4bd9-926a-762ec0cf6cbd",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "The commands below allow displaying a sample review and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "697f2089-488b-4ec7-9727-b1643a7887aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review number---\n",
      "14932\n",
      "\n",
      "---review---\n",
      "[1, 18058, 17467, 80, 115, 859, 14, 403, 11, 27, 113, 14, 9, 4, 20, 63, 2164, 27, 8510, 12, 16, 626, 19, 76, 3401, 21, 8072, 913, 5, 2984, 8, 4376, 4118, 10940, 18, 94, 1180, 5, 10387, 17467, 69, 8, 1276, 20511, 98, 18, 4, 10940, 28737, 515, 103, 94, 766, 29, 805, 16027, 83, 2420, 21, 1196, 3605, 94, 6, 55, 78, 20, 19, 527, 116, 78, 489, 2430, 5, 1235, 881, 469, 4, 20, 17467, 272, 40, 6, 415, 2073, 39, 49, 3497, 146, 31, 7, 4, 2411, 3741, 37, 219, 18058, 86, 251, 86, 123, 11, 1716, 4, 1221, 71, 38, 1100, 15, 91, 7, 98, 317, 4, 1716, 159, 4, 22328, 806, 637, 24, 386, 14, 31, 8, 259]\n",
      "\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "idx = rd.randint(len(X_train))\n",
    "\n",
    "print('---review number---')\n",
    "print(idx)\n",
    "\n",
    "print('\\n---review---')\n",
    "print(X_train[idx])\n",
    "\n",
    "print('\\n---label---')\n",
    "print(y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324158e-1507-4166-92ef-17f9754f5861",
   "metadata": {},
   "source": [
    "The review is stored as a sequence of integers. These are word IDs that have been pre-assigned to individual words, based on their frequencies: the more frequent a word, the lower the integer. The label is an integer (0 for negative, 1 for positive).\n",
    "\n",
    "To decode the review, we need to use the vocabulary, _i.e._, the dictionary that associates each word with its unique integer ID, which is available via the `get_word_index()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d7ae1a01-aafe-424f-a258-cf317a3f2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pad_char = 0\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "\n",
    "word_to_idx = imdb.get_word_index()\n",
    "idx_to_word = {i+index_from: w for (w, i) in word_to_idx.items()}\n",
    "idx_to_word[pad_char] = \"[PAD]\"\n",
    "idx_to_word[start_char] = \"[START]\"\n",
    "idx_to_word[oov_char] = \"[OOV]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5f154-6256-4112-8462-d80be4a535cb",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Write a function that displays a review in a readable form along with its label.</span>\n",
    "\n",
    "Keep a similar display to the one suggested above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2d771-5e3a-474e-a71c-d44c94080845",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def decodeReview(idx):\n",
    "    '''\n",
    "    Converts the encoded idx-th review to human readable form.\n",
    "    Displays the review number, the review in words and the label\n",
    "    '''\n",
    "    [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ea724d3a-805c-4106-bce7-173f6470539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/decodeReview.py\n",
    "def decodeReview(idx):\n",
    "    '''\n",
    "    Converts the encoded idx-th review to human readable form.\n",
    "    Displays the review number, the review in words and the label\n",
    "    '''\n",
    "    print('---review number---')\n",
    "    print(idx)\n",
    "\n",
    "    print('\\n---review in words---')\n",
    "    print(\" \".join(idx_to_word[i] for i in X_train[idx]))\n",
    "\n",
    "    print('\\n---label---')\n",
    "    print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "41dd2b39-656e-4a68-9886-d013c25f0d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review number---\n",
      "14932\n",
      "\n",
      "---review in words---\n",
      "[START] baba rajinikanth will never forget this name in his life this is the movie which caused his downfall it was released with much hype but crashed badly and laid to severe financial losses for its producers and distributors rajinikanth had to personally repay them for the losses incurred soon after its release he tried venturing into politics but failed miserably its a very bad movie with horrible acting bad quality makeup and pathetic screenplay throughout the movie rajinikanth looks like a person suffering from some disease i'm one of the unfortunate souls who saw baba first day first show in theatre the audiences were so bored that most of them left the theatre before the intermission sorry i'll not recommend this one to anyone\n",
      "\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "decodeReview(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bb9e8-3dee-44fe-92a8-bc550315fc50",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** What is the proportion of positive reviews in the training dataset? And in the test dataset?</span>\n",
    "\n",
    "This question can be answered using a barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836342a5-87df-4ec8-986f-563a81a2eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Proportion of positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3cb933fe-182e-472c-8450-2d70828b0d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribution:  {0: 12500, 1: 12500}\n",
      "y_test distribution:  {0: 12500, 1: 12500}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/imdb/positiveProportion.py\n",
    "plt.figure(figsize = (8,3))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.countplot(x=y_train)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"y_train\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.countplot(x=y_test)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"y_test\")\n",
    "\n",
    "\n",
    "unique,  counts = np.unique(y_train, return_counts = True)\n",
    "print(\"y_train distribution: \", dict(zip(unique,counts)))\n",
    "\n",
    "unique,  counts = np.unique(y_test, return_counts = True)\n",
    "print(\"y_test distribution: \", dict(zip(unique,counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3466221-afef-4569-b938-3a5ae2fc9f55",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** How many different words does this database contain?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2e24c-bddd-41f6-85cc-a3938afab55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "vocab_size = ...\n",
    "\n",
    "print('%d unique words found' % vocab_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a4bf6811-438e-4642-9b31-6e49536b97c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584 unique words found\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/imdb/vocab_size.py\n",
    "vocab_size = len(imdb.get_word_index())\n",
    "print('%d unique words found' % vocab_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cef1b-cdcf-45b0-86b8-210525b53f65",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Question:** Are all reviews the same length? If not, what is their maximum length?</span>\n",
    "\n",
    "This question can be answered using an histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5ccf3-b7aa-4b0a-8aa9-cd80eb2265fa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Lengths of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "84721a47-77f6-472f-984a-f6e489c937f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 2494\n",
      "Minimum review length: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/imdb/reviewsLengths.py\n",
    "train_lengths = []\n",
    "for x in X_train:\n",
    "    train_lengths.append(len(x))\n",
    "    \n",
    "test_lengths = []\n",
    "for x in X_test:\n",
    "    test_lengths.append(len(x))\n",
    "    \n",
    "    \n",
    "plt.figure(figsize = (10,6))\n",
    "sns.histplot(x=train_lengths,color='orange',alpha=.8)\n",
    "sns.histplot(x=test_lengths,alpha=.5)\n",
    "plt.legend(['train lengths','test lengths'])    \n",
    "\n",
    "\n",
    "print('Maximum review length: {}'.format(max(train_lengths+test_lengths)))\n",
    "print('Minimum review length: {}'.format(min(train_lengths+test_lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5573faf-8645-44c4-bfb0-48f4b949bbcf",
   "metadata": {},
   "source": [
    "### Sequences Padding\n",
    "\n",
    "The reviews have a variable number of words, while the network has a fixed number of neurons. To get a fixed length input, we can simply truncate the reviews to a fixed number of words, say $\\texttt{max_words=200}$. To facilitate learning, we will also limit ourselves to the $\\texttt{vocab_size=10000}$ most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a604b375-3eb0-4785-a96a-076088893e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "60e1f3ad-6907-4a6b-9fb8-c64828665dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_words = 200\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(start_char=1, oov_char=2, index_from=3, num_words = vocab_size)\n",
    "\n",
    "X_train_pad = sequence.pad_sequences(X_train, value=0, padding='post', maxlen=max_words)\n",
    "X_test_pad = sequence.pad_sequences(X_test, value=0, padding='post', maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e95cf-98a2-439b-bd18-1c6ffe9bd09b",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Check that the size of the reviews is now equal to $\\texttt{max_words}$ for each of them.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173e230-e8aa-488c-99cd-05b6cec5c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Lengths of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d82d19b7-f34d-40ec-9193-509423364404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 200\n",
      "Minimum review length: 200\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/imdb/paddingLengths.py\n",
    "lengths = []\n",
    "for x in X_train_pad+X_test_pad:\n",
    "    lengths.append(len(x))\n",
    "    \n",
    "print('Maximum review length: {}'.format(max(lengths)))\n",
    "print('Minimum review length: {}'.format(min(lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d855fcf-62ed-4ee9-8920-acadd29156b4",
   "metadata": {},
   "source": [
    "Let us see the effect of padding and truncation at the most frequent words on the previously displayed idx-th review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0c6d2e49-d0d9-4e71-806c-d17872c48c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review number---\n",
      "14932\n",
      "\n",
      "---review in words---\n",
      "[START] [OOV] [OOV] will never forget this name in his life this is the movie which caused his downfall it was released with much hype but crashed badly and laid to severe financial [OOV] for its producers and [OOV] [OOV] had to personally [OOV] them for the [OOV] [OOV] soon after its release he tried [OOV] into politics but failed miserably its a very bad movie with horrible acting bad quality makeup and pathetic screenplay throughout the movie [OOV] looks like a person suffering from some disease i'm one of the unfortunate souls who saw [OOV] first day first show in theatre the audiences were so bored that most of them left the theatre before the [OOV] sorry i'll not recommend this one to anyone\n",
      "\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "decodeReview(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6fdc4-fee5-4070-80c8-0fe5b8e07399",
   "metadata": {},
   "source": [
    "## RNN for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aecbc185-fa3c-48fd-b2d8-d9fdda80177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, SimpleRNN, LSTM, Dense, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6200be4-1088-4b0b-b37b-e512ef8ea133",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Design a RNN model for sentiment analysis.</span>\n",
    "\n",
    "The first layer must be an [`Embedding`](https://keras.io/api/layers/core_layers/embedding/) layer. To prevent gradient vanishing, choose a suitable recurrent network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9040f769-e436-46a9-8251-6ad95a8f5dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 32)           320000    \n",
      "=================================================================\n",
      "Total params: 320,000\n",
      "Trainable params: 320,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 11:19:50.507261: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-06 11:19:50.510274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 11:19:50.513657: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "### TO BE COMPLETED ### \n",
    "embedding_size = 32\n",
    "\n",
    "rnn = Sequential(name=\"RNN\")\n",
    "rnn.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "[...]\n",
    "\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0503022c-2e7a-4df3-80eb-7ed88a7f67e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [186]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m rnn \u001b[38;5;241m=\u001b[39m Sequential(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m rnn\u001b[38;5;241m.\u001b[39madd(Embedding(vocab_size, embedding_size, input_length\u001b[38;5;241m=\u001b[39mmax_words))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43membedding_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m rnn\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m      8\u001b[0m rnn\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:517\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 517\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:223\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_explicit_input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    221\u001b[0m   \u001b[38;5;66;03m# If the model is being built continuously on top of an input layer:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m   \u001b[38;5;66;03m# refresh its output.\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m   output_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nest\u001b[38;5;241m.\u001b[39mflatten(output_tensor)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:660\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m _standardize_args(inputs,\n\u001b[1;32m    655\u001b[0m                                                      initial_state,\n\u001b[1;32m    656\u001b[0m                                                      constants,\n\u001b[1;32m    657\u001b[0m                                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 660\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras_tensor\u001b[38;5;241m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:863\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m--> 863\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    867\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1157\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args_if_ragged(is_ragged_input, mask)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# LSTM does not support constants. Ignore it during process.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m inputs, initial_state, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m   1160\u001b[0m   mask \u001b[38;5;241m=\u001b[39m mask[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:859\u001b[0m, in \u001b[0;36mRNN._process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    857\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m   initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(initial_state) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates):\n\u001b[1;32m    862\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer has \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    863\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m states but was passed \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(initial_state)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    864\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m initial states.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:642\u001b[0m, in \u001b[0;36mRNN.get_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    640\u001b[0m dtype \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_initial_state_fn:\n\u001b[0;32m--> 642\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m \u001b[43mget_initial_state_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m   init_state \u001b[38;5;241m=\u001b[39m _generate_zero_filled_state(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mstate_size,\n\u001b[1;32m    646\u001b[0m                                            dtype)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:2506\u001b[0m, in \u001b[0;36mLSTMCell.get_initial_state\u001b[0;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_initial_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 2506\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43m_generate_zero_filled_state_for_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2507\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:2987\u001b[0m, in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[0;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2985\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(inputs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2986\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_zero_filled_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:3003\u001b[0m, in \u001b[0;36m_generate_zero_filled_state\u001b[0;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[1;32m   3000\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39mzeros(init_state_size, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   3002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mis_nested(state_size):\n\u001b[0;32m-> 3003\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_zeros\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3005\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m create_zeros(state_size)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py:3000\u001b[0m, in \u001b[0;36m_generate_zero_filled_state.<locals>.create_zeros\u001b[0;34m(unnested_state_size)\u001b[0m\n\u001b[1;32m   2998\u001b[0m flat_dims \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(unnested_state_size)\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[1;32m   2999\u001b[0m init_state_size \u001b[38;5;241m=\u001b[39m [batch_size_tensor] \u001b[38;5;241m+\u001b[39m flat_dims\n\u001b[0;32m-> 3000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2819\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2819\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2820\u001b[0m   tensor\u001b[38;5;241m.\u001b[39m_is_zeros_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2821\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2868\u001b[0m, in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2865\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   2866\u001b[0m     \u001b[38;5;66;03m# Create a constant if it won't be very big. Otherwise create a fill\u001b[39;00m\n\u001b[1;32m   2867\u001b[0m     \u001b[38;5;66;03m# op to prevent serialized GraphDefs from becoming too large.\u001b[39;00m\n\u001b[0;32m-> 2868\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_constant_if_small\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2870\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:2804\u001b[0m, in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_if_small\u001b[39m(value, shape, dtype, name):\n\u001b[1;32m   2803\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m   2805\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant(value, shape\u001b[38;5;241m=\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   2806\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;66;03m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3051\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2933\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2935\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2936\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m \u001b[38;5;124;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2938\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;124;03m    10\u001b[39;00m\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:852\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 852\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    853\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert a symbolic Tensor (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) to a numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    854\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This error may indicate that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to pass a Tensor to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a NumPy call, which is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "# %load solutions/imdb/rnn.py\n",
    "embedding_size = 32\n",
    "\n",
    "rnn = Sequential(name=\"RNN\")\n",
    "rnn.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "rnn.add(LSTM(int(.5*embedding_size)))\n",
    "rnn.add(Dropout(0.1))\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790cd29-8efe-4323-8d8e-636b552825de",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Performing the learning.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0d5e2-9a27-4726-bd1d-454f225cdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train_pad[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train_pad[batch_size:]\n",
    "\n",
    "\n",
    "rnn.compile(loss=..., \n",
    "             optimizer=..., \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_rnn = rnn.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f99f0b1-e4bd-4ed7-acbf-6f3fec9be06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 11:20:33.660467: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-12-06 11:20:33.732971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4994 binary_crossentropy\n        bce = target * math_ops.log(output + epsilon())\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1496 _mul_dispatch\n        return multiply(x, y, name=name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:518 multiply\n        return gen_math_ops.mul(x, y, name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:6077 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 100 and 200 for '{{node binary_crossentropy/mul}} = Mul[T=DT_FLOAT](binary_crossentropy/Cast, binary_crossentropy/Log)' with input shapes: [100,1], [100,200,32].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [188]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m X_train_rnn, y_train_rnn \u001b[38;5;241m=\u001b[39m X_train_pad[batch_size:], y_train[batch_size:]\n\u001b[1;32m      9\u001b[0m rnn\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m              optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m history_rnn \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1608 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4994 binary_crossentropy\n        bce = target * math_ops.log(output + epsilon())\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1496 _mul_dispatch\n        return multiply(x, y, name=name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:518 multiply\n        return gen_math_ops.mul(x, y, name)\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:6077 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /usr/local/insa/anaconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 100 and 200 for '{{node binary_crossentropy/mul}} = Mul[T=DT_FLOAT](binary_crossentropy/Cast, binary_crossentropy/Log)' with input shapes: [100,1], [100,200,32].\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/imdb/rnnTraining.py\n",
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "rnn.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_rnn = rnn.fit(X_train_rnn, \n",
    "                    y_train_rnn, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a15083-b62d-4f38-b9f0-d20d61eab224",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Visualize the learning process.</span>\n",
    "\n",
    "Write a function that allows to represent on two different figures the accuracy on one hand, and the loss on the other hand, each for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e2881-62e5-45f4-89b7-b37903fa9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "def plotTraining(history):\n",
    "    [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c3829-0d53-4e1c-bc06-3308c4d4a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/plotTraining.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d4c15-7cbe-4c9c-882c-f343c8215dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTraining(history_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237b8c5-61bf-48bc-9ee5-7da2c5fb0ed1",
   "metadata": {},
   "source": [
    "## Bidirectional RNN\n",
    "\n",
    "As defined, this network introduces a causal structure into the data. Also, for text processing, we often prefer a bidirectional network. To do this, we can use the [`Bidirectional`](https://keras.io/api/layers/recurrent_layers/bidirectional/) command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee2e3c-588b-45f4-abff-f59217850130",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "bi_rnn = Sequential(name=\"Bidirectional_RNN\")\n",
    "bi_rnn.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "bi_rnn.add(Bidirectional(LSTM(int(.5*embedding_size))))  ### NEW ###\n",
    "bi_rnn.add(Dropout(0.1))\n",
    "bi_rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(bi_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a81c21-bed6-4f9d-b8e8-c2f1cb251a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "bi_rnn.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_bi_rnn = bi_rnn.fit(X_train_rnn, \n",
    "                    y_train_rnn, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "plotTraining(history_bi_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023b1b0-0e6d-4d76-bf53-1abb53b34dad",
   "metadata": {},
   "source": [
    "Thanks to the $\\texttt{return_sequences}$ option, we can easily stack several RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b9883-309f-40b8-99c5-b1706115dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "bi2_rnn = Sequential(name=\"Double_Bidirectional_RNN\")\n",
    "bi2_rnn.add(Embedding(vocab_size, embedding_size, input_length=max_words))\n",
    "bi2_rnn.add(Bidirectional(LSTM(int(.5*embedding_size), return_sequences = True)))\n",
    "bi2_rnn.add(Bidirectional(LSTM(int(.5*embedding_size), return_sequences = False)))\n",
    "bi2_rnn.add(Dropout(0.1))\n",
    "bi2_rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(bi2_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7ef75-0bcf-4cce-b16f-962448b79d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epochs = 8\n",
    "\n",
    "X_valid, y_valid = X_train_pad[:batch_size], y_train[:batch_size]\n",
    "X_train_rnn, y_train_rnn = X_train_pad[batch_size:], y_train[batch_size:]\n",
    "\n",
    "\n",
    "bi2_rnn.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history_bi2_rnn = bi2_rnn.fit(X_train_rnn, \n",
    "                    y_train_rnn, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=num_epochs)\n",
    "\n",
    "plotTraining(history_bi2_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1239e-fc01-4e3e-80f4-b90cf13449b6",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ffb9e-f111-421b-b807-2d9e7108662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d910c-b6f3-4190-bf04-64b7cd2bfdd0",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Compare the confusion matrices for the three models proposed above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9feee-09c1-4900-96a0-4af1f97d8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Compare the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60fa15-4e03-4779-939d-21543df46dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/confusion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d183f7d-c21b-4417-ab91-102b43e604bd",
   "metadata": {},
   "source": [
    "## MLP for Sentiment Analysis\n",
    "\n",
    "Just to be sure of the usefulness of a recurrent network, we decide to test a \"simple\" perceptron on the IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c556d-97ab-4d2d-8471-4feb3a050909",
   "metadata": {},
   "source": [
    "##### <span style=\"color:purple\">**Todo:** Compare the above results with those of an MLP. Conclude.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38429f1f-d6d2-4111-8a23-4dc706e9c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO BE COMPLETED ### \n",
    "\n",
    "# Comparison with a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7eb79-76ae-4a5a-89fe-39197ef46b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/imdb/mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2b16d-f333-49f6-b0b7-7daef40cba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2541478-c6fa-4d0b-bbfb-3ddc821ca33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
